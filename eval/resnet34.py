# VoxCeleb EER 
# import os
# import torch
# import numpy as np
# from tqdm import tqdm
# import soundfile as sf
# from sklearn.metrics import roc_curve
# import sys

# # ëª¨ë¸ import ê²½ë¡œ ì¶”ê°€ (í•„ìš” ì‹œ ì¡°ì •)
# sys.path.append("/home/eoil/AGENT/")  # src ê¸°ì¤€
# from ResNetModels.ResNetSE34V2 import MainModel

# # ì„¤ì •
# MODEL_PATH = "./ResNetModels/baseline_v2_ap.model"  # ì ˆëŒ€ê²½ë¡œ ê°€ëŠ¥
# DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
# WAV_ROOT = "/home/eoil/AGENT/VoxCeleb/vox1_test_wav/wav"
# PROTOCOL_FILE = "/home/eoil/AGENT/VoxCeleb/veri_test2.txt"

# # âœ… ëª¨ë¸ ì´ˆê¸°í™”
# model = MainModel().to(DEVICE)

# # âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë”©
# checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
# state_dict = checkpoint.get("model", checkpoint)

# # âœ… "__S__." ë˜ëŠ” "__L__." prefix ì œê±°
# new_state_dict = {}
# for k, v in state_dict.items():
#     if k.startswith("__S__."):
#         new_key = k.replace("__S__.", "")
#     elif k.startswith("__L__."):
#         continue  # Loss ê´€ë ¨ í‚¤ëŠ” ëª¨ë¸ì— í•„ìš” ì—†ìŒ
#     else:
#         new_key = k
#     new_state_dict[new_key] = v

# # âœ… ë¡œë”©
# model.load_state_dict(new_state_dict, strict=True)
# model.eval()


# # âœ… ì„ë² ë”© ì¶”ì¶œ í•¨ìˆ˜
# def extract_embedding(wav_path):
#     wav, sr = sf.read(wav_path)
#     wav_tensor = torch.tensor(wav, dtype=torch.float32).unsqueeze(0).to(DEVICE)
#     with torch.no_grad():
#         embedding = model(wav_tensor).squeeze().cpu().numpy()
#     return embedding

# # âœ… í‰ê°€ ë£¨í”„
# embeddings = {}
# scores, labels = [], []

# with open(PROTOCOL_FILE, "r") as f:
#     for line in tqdm(f.readlines(), desc="Evaluating ResNetSE34V2"):
#         label, utt1, utt2 = line.strip().split()
#         path1 = os.path.join(WAV_ROOT, utt1)
#         path2 = os.path.join(WAV_ROOT, utt2)

#         if utt1 not in embeddings:
#             embeddings[utt1] = extract_embedding(path1)
#         if utt2 not in embeddings:
#             embeddings[utt2] = extract_embedding(path2)

#         emb1 = embeddings[utt1]
#         emb2 = embeddings[utt2]

#         score = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))
#         scores.append(score)
#         labels.append(int(label))

# # âœ… EER ê³„ì‚°
# fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)
# fnr = 1 - tpr
# eer_idx = np.nanargmin(np.abs(fnr - fpr))
# eer = (fpr[eer_idx] + fnr[eer_idx]) / 2
# eer_threshold = thresholds[eer_idx]

# print(f"\nâœ… ResNetSE34V2 ASV EER: {eer * 100:.2f}%")
# print(f"âœ… Threshold at EER: {eer_threshold:.4f}")
###############################################################
# VoxCeleb score
# import os
# import torch
# import numpy as np
# from tqdm import tqdm
# import soundfile as sf
# import sys

# # ëª¨ë¸ import ê²½ë¡œ ì¶”ê°€ (í•„ìš” ì‹œ ì¡°ì •)
# sys.path.append("/home/eoil/AGENT/")  # src ê¸°ì¤€
# from ResNetModels.ResNetSE34V2 import MainModel

# # ===== ì„¤ì • =====
# MODEL_PATH = "./ResNetModels/baseline_v2_ap.model"  # ì ˆëŒ€ê²½ë¡œ ê°€ëŠ¥
# DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ENROLL_ROOT = "/home/eoil/AGENT/VoxCeleb1/test/wav"              # âœ… enroll ì˜¤ë””ì˜¤
# TEST_ROOT   = "/home/eoil/AGENT/adv_examples/both_agent_004"     # âœ… adversarial/test ì˜¤ë””ì˜¤

# PROTOCOL_FILE = "/home/eoil/AGENT/VoxCeleb1/experiments/nontarget_4000_agent.txt"
# OUTPUT_FILE   = "/home/eoil/AGENT/VoxCeleb1/experiments/results/resnet34.txt"

# # ===== ëª¨ë¸ ì´ˆê¸°í™” =====
# model = MainModel().to(DEVICE)

# # ì²´í¬í¬ì¸íŠ¸ ë¡œë”©
# checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
# state_dict = checkpoint.get("model", checkpoint)

# # "__S__." ë˜ëŠ” "__L__." prefix ì œê±°
# new_state_dict = {}
# for k, v in state_dict.items():
#     if k.startswith("__S__."):
#         new_key = k.replace("__S__.", "")
#     elif k.startswith("__L__."):
#         continue  # Loss ê´€ë ¨ í‚¤ëŠ” ëª¨ë¸ì— í•„ìš” ì—†ìŒ
#     else:
#         new_key = k
#     new_state_dict[new_key] = v

# model.load_state_dict(new_state_dict, strict=True)
# model.eval()

# # ===== ì„ë² ë”© ì¶”ì¶œ í•¨ìˆ˜ =====
# def extract_embedding(wav_path):
#     wav, sr = sf.read(wav_path)
#     wav_tensor = torch.tensor(wav, dtype=torch.float32).unsqueeze(0).to(DEVICE)
#     with torch.no_grad():
#         embedding = model(wav_tensor).squeeze().cpu().numpy()
#     return embedding

# # ===== í‰ê°€ ë£¨í”„ =====
# embeddings = {}

# with open(PROTOCOL_FILE, "r") as f, open(OUTPUT_FILE, "w") as fout:
#     for line in tqdm(f.readlines(), desc="Evaluating ResNetSE34V2"):
#         label, utt1, utt2 = line.strip().split()
        
#         # enrollì€ ENROLL_ROOT, testëŠ” TEST_ROOT
#         path1 = os.path.join(ENROLL_ROOT, utt1)
#         path2 = os.path.join(TEST_ROOT, utt2)

#         if utt1 not in embeddings:
#             embeddings[utt1] = extract_embedding(path1)
#         if utt2 not in embeddings:
#             embeddings[utt2] = extract_embedding(path2)

#         emb1 = embeddings[utt1]
#         emb2 = embeddings[utt2]

#         score = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))

#         # íŒŒì¼ì— ê¸°ë¡ (label, utt1, utt2, score)
#         fout.write(f"{label} {utt1} {utt2} {score:.6f}\n")

# print(f"\nâœ… ì ìˆ˜ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {OUTPUT_FILE}")


#######################################################################################################################
# ASVspoof nontarget score
# import os
# import sys
# import glob
# import torch
# import numpy as np
# import soundfile as sf
# from tqdm import tqdm

# # ===== ê²½ë¡œ/ì„¤ì • =====
# AUDIO_DIR = "/home/eoil/AGENT/adv_examples_resnet/both_agent_001"
# PROTOCOL_FILE = "/home/eoil/AGENT/LA/ASVspoof2019_LA_asv_protocols/ASVspoof2019.LA.asv.eval.gi.trl.txt"
# ENROLL_ROOT = "/home/eoil/AGENT/enr_audio/eval"
# OUTPUT_TXT = "/home/eoil/AGENT/ICASSP2026/experiments/total_Score/resnet34.txt"

# # ===== ëª¨ë¸ ë¡œë“œ =====
# sys.path.append("/home/eoil/AGENT/")
# from ResNetModels.ResNetSE34V2 import MainModel

# MODEL_PATH = "./ResNetModels/baseline_v2_ap.model"
# DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# model = MainModel().to(DEVICE)
# checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
# state_dict = checkpoint.get("model", checkpoint)

# # "__S__." ì œê±°, "__L__." ì œì™¸
# new_state_dict = {}
# for k, v in state_dict.items():
#     if k.startswith("__S__."):
#         new_key = k.replace("__S__.", "")
#     elif k.startswith("__L__."):
#         continue
#     else:
#         new_key = k
#     new_state_dict[new_key] = v
# model.load_state_dict(new_state_dict, strict=True)
# model.eval()

# # ===== ìœ í‹¸ =====
# def read_mono_float32(wav_path):
#     wav, sr = sf.read(wav_path, dtype="float32")
#     if wav.ndim == 2:
#         wav = wav.mean(axis=1)
#     return wav

# @torch.no_grad()
# def extract_embedding(wav_path):
#     wav = read_mono_float32(wav_path)
#     wav_tensor = torch.from_numpy(wav).float().unsqueeze(0).to(DEVICE)
#     emb = model(wav_tensor).squeeze().cpu().numpy()
#     return emb

# def cosine(a, b):
#     denom = (np.linalg.norm(a) * np.linalg.norm(b))
#     if denom == 0:
#         return 0.0
#     return float(np.dot(a, b) / denom)

# # ===== í”„ë¡œí† ì½œ íŒŒì‹± =====
# nontarget_entries = []
# with open(PROTOCOL_FILE, "r") as f:
#     for line in f:
#         parts = line.strip().split()
#         if len(parts) < 4:
#             continue
#         spk_id, utt_id, label1, label2 = parts
#         # if label2 == "nontarget":
#         nontarget_entries.append((spk_id, utt_id, label1, label2))
# # print(f"ì´ nontarget ì—”íŠ¸ë¦¬ ê°œìˆ˜: {len(nontarget_entries)}")

# # ===== enroll cache =====
# enroll_cache = {}
# def find_enroll_path(spk_id):
#     if spk_id in enroll_cache:
#         return enroll_cache[spk_id]
#     pattern = os.path.join(ENROLL_ROOT, f"{spk_id}_*.flac")
#     candidates = sorted(glob.glob(pattern))
#     enroll_cache[spk_id] = candidates[0] if candidates else None
#     return enroll_cache[spk_id]

# # ===== scoring =====
# results, skipped = [], []
# embeddings, enr_embeddings = {}, {}

# for spk_id, utt_id, label1, label2 in tqdm(nontarget_entries, desc="Scoring nontarget only"):
#     test_path = os.path.join(AUDIO_DIR, f"{utt_id}.flac")
#     enroll_path = find_enroll_path(spk_id)
#     if not os.path.exists(test_path):
#         skipped.append((utt_id, "test audio not found"))
#         continue
#     if not enroll_path or not os.path.exists(enroll_path):
#         skipped.append((utt_id, f"enroll not found for {spk_id}"))
#         continue

#     try:
#         if test_path not in embeddings:
#             embeddings[test_path] = extract_embedding(test_path)
#         if enroll_path not in enr_embeddings:
#             enr_embeddings[enroll_path] = extract_embedding(enroll_path)

#         score = cosine(embeddings[test_path], enr_embeddings[enroll_path])
#         results.append((test_path, enroll_path, score, spk_id, utt_id, label1, label2))
#     except Exception as e:
#         skipped.append((utt_id, str(e)))

# # ===== ì €ì¥ =====
# os.makedirs(os.path.dirname(OUTPUT_TXT), exist_ok=True)

# with open(OUTPUT_TXT.replace(".txt","_score.txt"), "w") as fw:
#     fw.write("file,enroll_file,cosine_score\n")
#     for f1, enr, s, *_ in results:
#         fw.write(f"{f1},{enr},{s:.6f}\n")

# with open(OUTPUT_TXT.replace(".txt","_proto.txt"), "w") as fw:
#     for _, _, _, spk_id, utt_id, label1, label2 in results:
#         fw.write(f"{spk_id} {utt_id} {label1} {label2}\n")

# print(f"\nâœ… Done. Saved {len(results)} nontarget scores.")
# if skipped:
#     print(f"âš ï¸ Skipped {len(skipped)} entries. Examples:")
#     for p, msg in skipped[:5]:
#         print(f" - {p} :: {msg}")



#########################################################################
# LA 19ë¡œ ASV EER êµ¬í•˜ê¸° #

# import os
# import sys
# import glob
# import torch
# import numpy as np
# import soundfile as sf
# from tqdm import tqdm
# from sklearn.metrics import roc_curve

# # ===== ê²½ë¡œ/ì„¤ì • =====
# EVAL_DIR = "/home/eoil/AGENT/LA/ASVspoof2019_LA_eval/flac"
# PROTOCOL_FILE = "/home/eoil/AGENT/LA/ASVspoof2019_LA_asv_protocols/ASVspoof2019.LA.asv.eval.gi.trl.txt"
# ENROLL_ROOT = "/home/eoil/AGENT/enr_audio/eval"
# OUTPUT_TXT = "/home/eoil/AGENT/results/origin/LA19_(asv)resnet.txt"

# # ëª¨ë¸ import ê²½ë¡œ
# sys.path.append("/home/eoil/AGENT/")
# from ResNetModels.ResNetSE34V2 import MainModel

# MODEL_PATH = "./ResNetModels/baseline_v2_ap.model"
# DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# # ===== ëª¨ë¸ ë¡œë“œ =====
# model = MainModel().to(DEVICE)
# checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
# state_dict = checkpoint.get("model", checkpoint)
# new_state_dict = {}
# for k, v in state_dict.items():
#     if k.startswith("__S__."):
#         new_key = k.replace("__S__.", "")
#     elif k.startswith("__L__."):
#         continue
#     else:
#         new_key = k
#     new_state_dict[new_key] = v
# model.load_state_dict(new_state_dict, strict=True)
# model.eval()

# # ===== ìœ í‹¸ =====
# def read_mono_float32(path):
#     wav, sr = sf.read(path, dtype="float32")
#     if wav.ndim == 2:
#         wav = wav.mean(axis=1)
#     return wav

# @torch.no_grad()
# def extract_embedding(path):
#     wav = read_mono_float32(path)
#     wav_tensor = torch.from_numpy(wav).float().unsqueeze(0).to(DEVICE)
#     emb = model(wav_tensor).squeeze().detach().cpu().numpy()
#     return emb

# def cosine(a, b):
#     denom = (np.linalg.norm(a) * np.linalg.norm(b))
#     if denom == 0:
#         return 0.0
#     return float(np.dot(a, b) / denom)

# # ===== EVAL_DIR ì¸ë±ìŠ¤: base name -> full path =====
# base2path = {}
# for fn in os.listdir(EVAL_DIR):
#     if fn.lower().endswith(".flac"):
#         base2path[os.path.splitext(fn)[0]] = os.path.join(EVAL_DIR, fn)

# # ===== enroll_id -> enroll íŒŒì¼ ê²½ë¡œ ìºì‹œ =====
# enroll_cache = {}
# def find_enroll_path(enroll_id):
#     if enroll_id in enroll_cache:
#         return enroll_cache[enroll_id]
#     pattern = os.path.join(ENROLL_ROOT, f"{enroll_id}_*.flac")
#     cands = sorted(glob.glob(pattern))
#     enroll_cache[enroll_id] = cands[0] if cands else None
#     return enroll_cache[enroll_id]

# # ===== í”„ë¡œí† ì½œ íŒŒì‹± & ìŠ¤ì½”ì–´ë§ (target / nontargetë§Œ) =====
# scores, labels = [], []
# results = []   # (utt_id, enroll_id, utt_path, enroll_path, score, label)
# skipped = []
# emb_cache = {}

# with open(PROTOCOL_FILE, "r") as f:
#     lines = f.readlines()

# for line in tqdm(lines, desc="Scoring target/nontarget from protocol (eval set)"):
#     parts = line.strip().split()
#     if len(parts) < 4:
#         continue

#     enroll_id, utt_id, _, trial_type = parts[0], parts[1], parts[2].lower(), parts[3].lower()

#     # target / nontargetë§Œ ì‚¬ìš©
#     if trial_type not in ("target", "nontarget"):
#         continue

#     utt_path = base2path.get(utt_id)
#     if not utt_path or not os.path.exists(utt_path):
#         skipped.append((utt_id, "utt file not found in EVAL_DIR"))
#         continue

#     enroll_path = find_enroll_path(enroll_id)
#     if not enroll_path or not os.path.exists(enroll_path):
#         skipped.append((utt_id, f"enroll not found for {enroll_id}"))
#         continue

#     try:
#         if utt_path not in emb_cache:
#             emb_cache[utt_path] = extract_embedding(utt_path)
#         if enroll_path not in emb_cache:
#             emb_cache[enroll_path] = extract_embedding(enroll_path)

#         s = cosine(emb_cache[utt_path], emb_cache[enroll_path])
#         y = 1 if trial_type == "target" else 0

#         scores.append(s)
#         labels.append(y)
#         results.append((utt_id, enroll_id, utt_path, enroll_path, s, y))
#     except Exception as e:
#         skipped.append((utt_id, str(e)))

# # ===== EER ê³„ì‚° (target=1, nontarget=0) =====
# if len(scores) == 0:
#     raise SystemExit("No valid trials to score. Check EVAL_DIR and protocol matching.")

# labels = np.asarray(labels)
# scores = np.asarray(scores)
# fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)
# fnr = 1 - tpr
# idx = np.nanargmin(np.abs(fnr - fpr))
# eer = (fnr[idx] + fpr[idx]) / 2
# eer_thr = thresholds[idx]

# print(f"\nâœ… #used trials: {len(scores)} | #skipped: {len(skipped)}")
# print(f"âœ… ASV EER (eval target/nontarget): {eer * 100:.2f}%")
# print(f"âœ… Threshold at EER: {eer_thr:.6f}")

# if skipped:
#     print("âš ï¸ Skipped examples (first few):")
#     for u, msg in skipped[:8]:
#         print(f" - {u}: {msg}")

# # ===== ì ìˆ˜ ì €ì¥ (enroll_id, utt_id êµ¬ë¶„ í¬í•¨) =====
# os.makedirs(os.path.dirname(OUTPUT_TXT), exist_ok=True)
# with open(OUTPUT_TXT, "w", encoding="utf-8") as fw:
#     fw.write("utt_id,enroll_id,file,enroll_file,cosine_score,label(target=1,nontarget=0)\n")
#     for utt_id, enroll_id, fpath, epath, s, y in results:
#         fw.write(f"{utt_id},{enroll_id},{fpath},{epath},{s:.6f},{y}\n")

# print(f"ğŸ’¾ Saved scores to: {OUTPUT_TXT}")

#######################################################################

# # ASVspoof ì ìˆ˜
import os
import sys
import glob
import torch
import numpy as np
import soundfile as sf
from tqdm import tqdm

# ===== ê²½ë¡œ/ì„¤ì • =====
AUDIO_DIR = "/home/eoil/AGENT/adv_examples/ab/AGENT_simple/both_agent_008"
OUTPUT_TXT = "/home/eoil/AGENT/ICASSP2026/experiments/results/AB/simple/resnet34.txt"
ENROLL_ROOT = "/home/eoil/AGENT/enr_audio/eval"

# ëª¨ë¸ import ê²½ë¡œ
sys.path.append("/home/eoil/AGENT/")
from ResNetModels.ResNetSE34V2 import MainModel

MODEL_PATH = "./ResNetModels/baseline_v2_ap.model"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ===== ëª¨ë¸ ë¡œë“œ =====
model = MainModel().to(DEVICE)
checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
state_dict = checkpoint.get("model", checkpoint)

# "__S__." prefix ì œê±°, "__L__."(loss ê´€ë ¨) í‚¤ ì œì™¸
new_state_dict = {}
for k, v in state_dict.items():
    if k.startswith("__S__."):
        new_key = k.replace("__S__.", "")
    elif k.startswith("__L__."):
        continue
    else:
        new_key = k
    new_state_dict[new_key] = v

model.load_state_dict(new_state_dict, strict=True)
model.eval()

# ===== ìœ í‹¸ =====
def read_mono_float32(wav_path):
    wav, sr = sf.read(wav_path, dtype="float32")
    if wav.ndim == 2:
        wav = wav.mean(axis=1)
    return wav

@torch.no_grad()
def extract_embedding(wav_path):
    wav = read_mono_float32(wav_path)
    wav_tensor = torch.from_numpy(wav).float().unsqueeze(0).to(DEVICE)
    emb = model(wav_tensor).squeeze().detach().cpu().numpy()
    return emb

def cosine(a, b):
    denom = (np.linalg.norm(a) * np.linalg.norm(b))
    if denom == 0:
        return 0.0
    return float(np.dot(a, b) / denom)

# ===== enroll_id -> enroll íŒŒì¼ ê²½ë¡œ ìºì‹œ =====
enroll_cache = {}
def find_enroll_path(enroll_id):
    if enroll_id in enroll_cache:
        return enroll_cache[enroll_id]
    pattern = os.path.join(ENROLL_ROOT, f"{enroll_id}_*.flac")
    candidates = sorted(glob.glob(pattern))
    enroll_cache[enroll_id] = candidates[0] if candidates else None
    return enroll_cache[enroll_id]

# ===== adversarial íŒŒì¼ ì „ë¶€ ìˆ˜ì§‘ =====
adv_files = sorted(glob.glob(os.path.join(AUDIO_DIR, "*.wav")))
print(f"ì´ adversarial íŒŒì¼ ê°œìˆ˜: {len(adv_files)}")

# ===== ì„ë² ë”© ìºì‹œ =====
embeddings = {}
enr_embeddings = {}

# ===== ìŠ¤ì½”ì–´ë§ =====
results = []
skipped = []

for adv_path in tqdm(adv_files, desc="Scoring all adversarial files"):
    fname = os.path.basename(adv_path)
    base = fname.replace(".wav", "")
    parts = base.split("_")

    if len(parts) < 5:
        skipped.append((fname, "Filename parsing failed"))
        continue

    utt_id = "_".join(parts[:3])     # LA_E_1006250
    enroll_id = "_".join(parts[3:])  # LA_0017

    enroll_path = find_enroll_path(enroll_id)
    if not enroll_path or not os.path.exists(enroll_path):
        skipped.append((fname, f"Enroll audio not found for {enroll_id}"))
        continue

    try:
        if adv_path not in embeddings:
            embeddings[adv_path] = extract_embedding(adv_path)
        if enroll_path not in enr_embeddings:
            enr_embeddings[enroll_path] = extract_embedding(enroll_path)

        s = cosine(embeddings[adv_path], enr_embeddings[enroll_path])
        results.append((utt_id, enroll_id, s))
    except Exception as e:
        skipped.append((fname, str(e)))


# ===== ê²°ê³¼ ì €ì¥ =====
os.makedirs(os.path.dirname(OUTPUT_TXT), exist_ok=True)
with open(OUTPUT_TXT, "w", encoding="utf-8") as fw:
    fw.write("utt_id,enroll_id,cosine_score\n")
    for utt_id, enroll_id, s in results:
        fw.write(f"{utt_id},{enroll_id},{s:.6f}\n")

print(f"\nâœ… Done. Saved {len(results)} scores to: {OUTPUT_TXT}")
if skipped:
    print(f"âš ï¸ Skipped {len(skipped)} entries. First few issues:")
    for p, msg in skipped[:8]:
        print(f" - {p} :: {msg}")
######################################################################################
# í”„ë¡œí† ì½œ í‰ê°€
# import os
# import sys
# import glob
# import torch
# import numpy as np
# import soundfile as sf
# from tqdm import tqdm

# # ===== ê²½ë¡œ/ì„¤ì • =====
# PROTOCOL_FILE = "/home/eoil/AGENT/ICASSP2026/experiments/protocol/target_4000.txt"
# AUDIO_DIR = "/home/eoil/AGENT/LA/ASVspoof2019_LA_eval/flac"
# OUTPUT_TXT = "/home/eoil/AGENT/ICASSP2026/experiments/results/findings/noatt/noatt_target_asv.txt"
# ENROLL_ROOT = "/home/eoil/AGENT/enr_audio/eval"

# # ëª¨ë¸ import ê²½ë¡œ
# sys.path.append("/home/eoil/AGENT/")
# from ResNetModels.ResNetSE34V2 import MainModel

# MODEL_PATH = "./ResNetModels/baseline_v2_ap.model"
# DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# # ===== ëª¨ë¸ ë¡œë“œ =====
# model = MainModel().to(DEVICE)
# checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
# state_dict = checkpoint.get("model", checkpoint)

# # "__S__." prefix ì œê±°, "__L__."(loss ê´€ë ¨) í‚¤ ì œì™¸
# new_state_dict = {}
# for k, v in state_dict.items():
#     if k.startswith("__S__."):
#         new_key = k.replace("__S__.", "")
#     elif k.startswith("__L__."):
#         continue
#     else:
#         new_key = k
#     new_state_dict[new_key] = v

# model.load_state_dict(new_state_dict, strict=True)
# model.eval()

# # ===== ìœ í‹¸ =====
# def read_mono_float32(wav_path):
#     wav, sr = sf.read(wav_path, dtype="float32")
#     if wav.ndim == 2:
#         wav = wav.mean(axis=1)
#     return wav

# @torch.no_grad()
# def extract_embedding(wav_path):
#     wav = read_mono_float32(wav_path)
#     wav_tensor = torch.from_numpy(wav).float().unsqueeze(0).to(DEVICE)
#     emb = model(wav_tensor).squeeze().detach().cpu().numpy()
#     return emb

# def cosine(a, b):
#     denom = (np.linalg.norm(a) * np.linalg.norm(b))
#     if denom == 0:
#         return 0.0
#     return float(np.dot(a, b) / denom)

# # ===== enroll_id -> enroll íŒŒì¼ ê²½ë¡œ ìºì‹œ =====
# enroll_cache = {}
# def find_enroll_path(enroll_id):
#     if enroll_id in enroll_cache:
#         return enroll_cache[enroll_id]
#     pattern = os.path.join(ENROLL_ROOT, f"{enroll_id}_*.flac")
#     candidates = sorted(glob.glob(pattern))
#     enroll_cache[enroll_id] = candidates[0] if candidates else None
#     return enroll_cache[enroll_id]

# # ===== í”„ë¡œí† ì½œ ì½ê¸° =====
# protocol_entries = []
# with open(PROTOCOL_FILE, "r") as f:
#     for line in f:
#         parts = line.strip().split()
#         if len(parts) < 4:
#             continue
#         enroll_id, utt_id, label, trial_type = parts
#         protocol_entries.append((enroll_id, utt_id, label, trial_type))

# print(f"ì´ í”„ë¡œí† ì½œ ì—”íŠ¸ë¦¬ ê°œìˆ˜: {len(protocol_entries)}")

# # ===== ì„ë² ë”© ìºì‹œ =====
# embeddings = {}
# enr_embeddings = {}

# # ===== ìŠ¤ì½”ì–´ë§ =====
# results = []
# skipped = []

# for enroll_id, utt_id, label, trial_type in tqdm(protocol_entries, desc="Scoring from protocol"):
#     adv_path = os.path.join(AUDIO_DIR, f"{utt_id}.flac")
#     if not os.path.exists(adv_path):
#         skipped.append((utt_id, f"Adversarial audio not found: {adv_path}"))
#         continue

#     enroll_path = find_enroll_path(enroll_id)
#     if not enroll_path or not os.path.exists(enroll_path):
#         skipped.append((utt_id, f"Enroll audio not found for {enroll_id}"))
#         continue

#     try:
#         if adv_path not in embeddings:
#             embeddings[adv_path] = extract_embedding(adv_path)
#         if enroll_path not in enr_embeddings:
#             enr_embeddings[enroll_path] = extract_embedding(enroll_path)

#         s = cosine(embeddings[adv_path], enr_embeddings[enroll_path])
#         results.append((utt_id, enroll_id, s, label, trial_type))
#     except Exception as e:
#         skipped.append((utt_id, str(e)))

# # ===== ê²°ê³¼ ì €ì¥ =====
# os.makedirs(os.path.dirname(OUTPUT_TXT), exist_ok=True)
# with open(OUTPUT_TXT, "w", encoding="utf-8") as fw:
#     fw.write("utt_id,enroll_id,cosine_score,label,trial_type\n")
#     for utt_id, enroll_id, s, label, trial_type in results:
#         fw.write(f"{utt_id},{enroll_id},{s:.6f},{label},{trial_type}\n")

# print(f"\nâœ… Done. Saved {len(results)} scores to: {OUTPUT_TXT}")
# if skipped:
#     print(f"âš ï¸ Skipped {len(skipped)} entries. First few issues:")
#     for p, msg in skipped[:8]:
#         print(f" - {p} :: {msg}")
